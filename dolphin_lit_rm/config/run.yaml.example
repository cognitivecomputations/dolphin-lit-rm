# Main run configuration
# Paths can be relative to the project root or absolute.

# Base directory for all runs. Each pipeline execution will create a subdirectory here.
# e.g., ./output/runs/run_20231120_103000_abcdef
runs_parent_dir: "./output/runs"
default_log_level: "INFO"

# API settings (can be overridden per stage)
# These are examples; use environment variables for sensitive keys in production.
default_llm_settings:
  api_base_url: "https://openrouter.ai/api/v1" # OpenAI-compatible endpoint
  api_key: "sk-" # or use "ENV:OPENAI_API_KEY"
  timeout_seconds: 60
  max_retries: 3
  max_concurrent_requests: 1

# Stage-specific configurations
ingestion:
  # No specific LLM settings for ingestion typically
  # max_items_per_dataset can be set in datasets.yaml

preprocessing:
  filter:
    min_response_tokens: 200
    max_response_tokens: 8000
    lang_id_threshold: 0.9 # for English
    # blacklist_regex_patterns: # List of regex patterns
    #   - "(?i)lorem ipsum"
    #   - "<html"
    deduplication_cache_db: "dedup_cache.lmdb" # Will be created in run_dir/artifacts/state/
  segmentation:
    max_chunk_tokens: 3800 # Target N-2k, e.g., 6000 - 2000
    sentence_overlap_count: 1 # Number of sentences to overlap
  prompt_reconstruction:
    model_name: "qwen/qwen3-30b-a3b" # Example
    max_response_tokens_for_reconstruction: 1024
    reconstructed_prompt_max_chars: 256
    # llm_settings can override default_llm_settings
    llm_settings:
      max_concurrent_requests: 500

classification:
  model_name: "qwen/qwen3-30b-a3b" # Example for zero-shot
  llm_settings:
    max_concurrent_requests: 500
  top_level_genres_for_prompt:
    - literary_novel
    - fantasy_novel
    - science_fiction_novel
    - horror_novel
    - thriller_suspense_novel
    - mystery_detective_novel
    - romance_novel
    - historical_fiction_novel
    - young_adult_novel
    - middle_grade_novel
    - shortform_story_literary
    - shortform_story_fantasy
    - shortform_story_science_fiction
    - shortform_story_horror
    - shortform_story_thriller
    - shortform_story_mystery
    - shortform_story_crime
    - shortform_story_romance
    - shortform_story_historical
    - shortform_story_humor
    - shortform_story_young_adult
    - shortform_story_other
    - flash_fiction
    - vignette
    - song_lyrics
    - narrative_poetry
    - dramatic_poetry
    - experimental_poetry
    - haiku_tanka
    - spoken_word_poetry
    - stage_play_script
    - screenplay
    - teleplay
    - radio_play_script
    - musical_libretto
    - comic_book_script
    - graphic_novel_script
    - japanese_manga
    - webcomic_script
    - videogame_script
    - interactive_fiction
    - rpg_transcript
    - rpg_transcript_erotic
    - rpg_scenario
    - academic_article
    - academic_book
    - dissertation_thesis
    - conference_paper
    - literature_review
    - research_proposal
    - textbook_chapter
    - news_report
    - investigative_journalism
    - feature_article
    - opinion_piece
    - editorial
    - column
    - profile_interview
    - review_article
    - blog_post
    - memoir
    - biography
    - personal_essay
    - travel_writing
    - nature_writing
    - food_writing
    - humor_nonfiction
    - diary_entry
    - political_speech
    - advocacy_paper
    - grant_proposal
    - marketing_copy
    - business_report
    - technical_manual
    - how_to_guide
    - popular_science
    - reference_entry
    - faq_document
    - legal_document
    - medical_info
    - case_study
    - social_media_post
    - forum_post
    - product_description
    - user_review
    - website_copy
    - email_newsletter
    - erotic_fiction
    - erotic_poetry
    - bdsm_scene_script
    - erotic_rp_log

normalization:
  # Quotas applied after classification, across the combined dataset.
  # Keys are 'class.top' or 'class.sub'. Values are max records.
  # 'default' applies to classes not explicitly listed.
  quotas:
    class.top:
      literary_novel: 1000
      fantasy_novel: 1000
      science_fiction_novel: 1000
      horror_novel: 1000
      thriller_suspense_novel: 1000
      mystery_detective_novel: 1000
      romance_novel: 1000
      historical_fiction_novel: 1000
      young_adult_novel: 1000
      middle_grade_novel: 1000
      shortform_story_literary: 1000
      shortform_story_fantasy: 1000
      shortform_story_science_fiction: 1000
      shortform_story_horror: 1000
      shortform_story_thriller: 1000
      shortform_story_mystery: 1000
      shortform_story_crime: 1000
      shortform_story_romance: 1000
      shortform_story_historical: 1000
      shortform_story_humor: 1000
      shortform_story_young_adult: 1000
      shortform_story_other: 1000
      flash_fiction: 1000
      vignette: 1000
      song_lyrics: 1000
      narrative_poetry: 1000
      dramatic_poetry: 1000
      experimental_poetry: 1000
      haiku_tanka: 1000
      spoken_word_poetry: 1000
      stage_play_script: 1000
      screenplay: 1000
      teleplay: 1000
      radio_play_script: 1000
      musical_libretto: 1000
      comic_book_script: 1000
      graphic_novel_script: 1000
      japanese_manga: 1000
      webcomic_script: 1000
      videogame_script: 1000
      interactive_fiction: 1000
      rpg_transcript: 1000
      rpg_transcript_erotic: 1000
      rpg_scenario: 1000
      academic_article: 1000
      academic_book: 1000
      dissertation_thesis: 1000
      conference_paper: 1000
      literature_review: 1000
      research_proposal: 1000
      textbook_chapter: 1000
      news_report: 1000
      investigative_journalism: 1000
      feature_article: 1000
      opinion_piece: 1000
      editorial: 1000
      column: 1000
      profile_interview: 1000
      review_article: 1000
      blog_post: 1000
      memoir: 1000
      biography: 1000
      personal_essay: 1000
      travel_writing: 1000
      nature_writing: 1000
      food_writing: 1000
      humor_nonfiction: 1000
      diary_entry: 1000
      political_speech: 1000
      advocacy_paper: 1000
      grant_proposal: 1000
      marketing_copy: 1000
      business_report: 1000
      technical_manual: 1000
      how_to_guide: 1000
      popular_science: 1000
      reference_entry: 1000
      faq_document: 1000
      legal_document: 1000
      medical_info: 1000
      case_study: 1000
      social_media_post: 1000
      forum_post: 1000
      product_description: 1000
      user_review: 1000
      website_copy: 1000
      email_newsletter: 1000
      erotic_fiction: 1000
      erotic_poetry: 1000
      bdsm_scene_script: 1000
      erotic_rp_log: 1000
  default_quota_per_class: 100


scoring:
  model_name: "qwen/qwen3-32b" # Example, Qwen-3-30B-Instruct
  max_tokens_per_metric_response: 8 # For parsing "0.xx"
  llm_settings:
    max_concurrent_requests: 500

postprocessing:
  calibration:
    enabled: true
    lower_percentile: 5
    upper_percentile: 95
  min_metrics_present_percent: 0.7 # Drop records with <70% of metrics scored
  splits:
    train: 0.90
    validation: 0.05
    test: 0.05
  final_dataset_name_prefix: "exp01"

# Tokenizer used for length checks, segmentation, etc.
# Can be a Hugging Face tokenizer name or path.
# If using tiktoken, this might be a model name like "gpt-4"
tokenizer_name: "gpt-4" # For tiktoken, or a HF tokenizer path